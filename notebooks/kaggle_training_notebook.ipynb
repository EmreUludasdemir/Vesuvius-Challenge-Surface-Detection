{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vesuvius Challenge Surface Detection - Kaggle Training\n",
    "\n",
    "**Optimized for Kaggle GPU (T4/P100 16GB)**\n",
    "\n",
    "## üöÄ Kullanƒ±m:\n",
    "1. Kaggle'da yeni notebook olu≈ütur\n",
    "2. Settings ‚Üí Accelerator ‚Üí **GPU T4 x2** se√ß\n",
    "3. Add Data ‚Üí Vesuvius Challenge dataset ekle\n",
    "4. Bu notebook'u kopyala-yapƒ±≈ütƒ±r\n",
    "5. **\"Save & Run All\"** (Commit) tƒ±kla\n",
    "6. Bilgisayarƒ± kapatabilirsin - Kaggle √ßalƒ±≈ümaya devam eder!\n",
    "\n",
    "## ‚è∞ S√ºre:\n",
    "- Training: ~3-4 saat (50 epoch)\n",
    "- GPU Quota: 30 saat/hafta (√ºcretsiz)\n",
    "- Max session: 9 saat\n",
    "\n",
    "## üíæ Output:\n",
    "- Model checkpoints: `/kaggle/working/checkpoints/`\n",
    "- Predictions: `/kaggle/working/outputs/`\n",
    "- Notebook commit edilince bunlar kaydedilir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Clone repository\n",
    "!git clone https://github.com/EmreUludasdemir/Vesuvius-Challenge-Surface-Detection.git\n",
    "%cd Vesuvius-Challenge-Surface-Detection\n",
    "\n",
    "print(\"‚úì Repository cloned!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Install missing packages (Kaggle already has most)\n",
    "!pip install -q segmentation-models-pytorch==0.3.3\n",
    "!pip install -q monai\n",
    "!pip install -q einops\n",
    "!pip install -q omegaconf\n",
    "\n",
    "print(\"‚úì Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Environment Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import psutil\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# Add to path\n",
    "sys.path.append('/kaggle/working/Vesuvius-Challenge-Surface-Detection')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"KAGGLE ENVIRONMENT INFO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# CPU & RAM\n",
    "print(f\"CPU cores: {psutil.cpu_count()}\")\n",
    "print(f\"Total RAM: {psutil.virtual_memory().total / 1024**3:.2f} GB\")\n",
    "print(f\"Available RAM: {psutil.virtual_memory().available / 1024**3:.2f} GB\")\n",
    "\n",
    "# GPU\n",
    "print(f\"\\nCUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    \n",
    "    # Memory benchmark\n",
    "    gpu_mem_total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    if gpu_mem_total < 20:\n",
    "        print(\"\\n‚ö†Ô∏è Low memory GPU detected (T4/P100)\")\n",
    "        print(\"   Using optimized config: batch_size=2, features=16\")\n",
    "        GPU_CONFIG = 'low_memory'\n",
    "    else:\n",
    "        print(\"\\n‚úì High memory GPU detected (A100)\")\n",
    "        print(\"   Using default config: batch_size=4, features=32\")\n",
    "        GPU_CONFIG = 'default'\n",
    "else:\n",
    "    print(\"\\n‚ùå No GPU available! Enable GPU in Settings.\")\n",
    "    GPU_CONFIG = 'cpu'\n",
    "\n",
    "# Directories\n",
    "print(f\"\\nWorking dir: {os.getcwd()}\")\n",
    "print(f\"Kaggle input: /kaggle/input/\")\n",
    "print(f\"Kaggle output: /kaggle/working/\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.preprocessing import VolumeLoader, PatchExtractor\n",
    "from src.data.augmentations import VolumeAugmentationPipeline, ZTranslationAugment\n",
    "from src.models.sobel_baseline import SobelSurfaceDetector\n",
    "from src.models.unet3d import UNet3DDepthInvariant, count_parameters\n",
    "from src.training.losses import CombinedLoss\n",
    "from src.training.trainer import Trainer, compute_dice, compute_iou\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(\"‚úì All modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle-optimized configuration\n",
    "CONFIG = {\n",
    "    # Data paths - ADJUST THESE!\n",
    "    'data_root': '/kaggle/input/vesuvius-challenge-ink-detection',  # Change to your dataset path\n",
    "    'fragment_id': 'train/1',  # Fragment to train on\n",
    "    \n",
    "    # Model (optimized for 16GB GPU)\n",
    "    'model': {\n",
    "        'in_channels': 65,\n",
    "        'out_channels': 1,\n",
    "        'base_features': 16 if GPU_CONFIG == 'low_memory' else 32,\n",
    "        'depth': 3 if GPU_CONFIG == 'low_memory' else 4,\n",
    "    },\n",
    "    \n",
    "    # Training (optimized for Kaggle)\n",
    "    'training': {\n",
    "        'num_epochs': 50,\n",
    "        'batch_size': 2 if GPU_CONFIG == 'low_memory' else 4,\n",
    "        'learning_rate': 1e-4,\n",
    "        'use_amp': True,  # Mixed precision - CRITICAL for memory\n",
    "        'num_workers': 2,\n",
    "        'save_every': 5,  # Save checkpoint every 5 epochs\n",
    "    },\n",
    "    \n",
    "    # Data\n",
    "    'data': {\n",
    "        'num_slices': 65,\n",
    "        'patch_size': 128 if GPU_CONFIG == 'low_memory' else 256,\n",
    "        'stride': 64 if GPU_CONFIG == 'low_memory' else 128,\n",
    "        'val_split': 0.2,\n",
    "    },\n",
    "    \n",
    "    # Paths\n",
    "    'checkpoint_dir': Path('/kaggle/working/checkpoints'),\n",
    "    'output_dir': Path('/kaggle/working/outputs'),\n",
    "}\n",
    "\n",
    "# Create directories\n",
    "CONFIG['checkpoint_dir'].mkdir(exist_ok=True)\n",
    "CONFIG['output_dir'].mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  GPU Config: {GPU_CONFIG}\")\n",
    "print(f\"  Batch size: {CONFIG['training']['batch_size']}\")\n",
    "print(f\"  Base features: {CONFIG['model']['base_features']}\")\n",
    "print(f\"  Patch size: {CONFIG['data']['patch_size']}\")\n",
    "print(f\"  Num epochs: {CONFIG['training']['num_epochs']}\")\n",
    "print(f\"\\n‚úì Configuration ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if data exists\n",
    "data_path = Path(CONFIG['data_root'])\n",
    "fragment_path = data_path / CONFIG['fragment_id']\n",
    "\n",
    "print(f\"Looking for data at: {fragment_path}\")\n",
    "\n",
    "if not fragment_path.exists():\n",
    "    print(\"\\n‚ùå ERROR: Data not found!\")\n",
    "    print(\"\\nAvailable paths in /kaggle/input/:\")\n",
    "    !ls -la /kaggle/input/\n",
    "    print(\"\\nPlease:\")\n",
    "    print(\"1. Add Vesuvius Challenge dataset in Kaggle notebook settings\")\n",
    "    print(\"2. Update CONFIG['data_root'] and CONFIG['fragment_id'] above\")\n",
    "    raise FileNotFoundError(f\"Fragment not found: {fragment_path}\")\n",
    "else:\n",
    "    print(f\"‚úì Data found!\\n\")\n",
    "    \n",
    "    # List contents\n",
    "    print(f\"Contents of {fragment_path}:\")\n",
    "    !ls -la {fragment_path}\n",
    "    \n",
    "    # Check for surface_volume\n",
    "    surface_volume_path = fragment_path / \"surface_volume\"\n",
    "    if surface_volume_path.exists():\n",
    "        num_slices = len(list(surface_volume_path.glob('*.tif')))\n",
    "        print(f\"\\n‚úì Found {num_slices} CT slices\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Warning: surface_volume directory not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Load volume\n",
    "print(\"Loading 3D volume...\")\n",
    "\n",
    "loader = VolumeLoader(\n",
    "    data_root=CONFIG['data_root'],\n",
    "    fragment_id=CONFIG['fragment_id'],\n",
    "    num_slices=CONFIG['data']['num_slices'],\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "volume = loader.load_volume()\n",
    "mask = loader.load_mask()\n",
    "labels = loader.load_labels()\n",
    "\n",
    "print(f\"\\nVolume shape: {volume.shape}\")\n",
    "print(f\"Volume range: [{volume.min():.3f}, {volume.max():.3f}]\")\n",
    "print(f\"Volume size: {volume.nbytes / 1024**2:.2f} MB\")\n",
    "\n",
    "if mask is not None:\n",
    "    print(f\"\\nMask shape: {mask.shape}\")\n",
    "    print(f\"Valid region: {mask.sum() / mask.size * 100:.2f}%\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No mask found - using full volume\")\n",
    "    mask = np.ones(volume.shape[1:], dtype=np.uint8)\n",
    "\n",
    "if labels is not None:\n",
    "    print(f\"\\nLabels shape: {labels.shape}\")\n",
    "    print(f\"Surface coverage: {labels.sum() / labels.size * 100:.2f}%\")\n",
    "else:\n",
    "    print(\"\\n‚ùå No labels found! Cannot train without ground truth.\")\n",
    "    print(\"This fragment may not have labels. Try a different fragment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize middle slice\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Volume\n",
    "axes[0].imshow(volume[32], cmap='gray')\n",
    "axes[0].set_title('Volume (Slice 32)')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Mask\n",
    "if mask is not None:\n",
    "    axes[1].imshow(mask, cmap='gray')\n",
    "    axes[1].set_title('Valid Region Mask')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "# Labels\n",
    "if labels is not None:\n",
    "    axes[2].imshow(labels, cmap='hot')\n",
    "    axes[2].set_title('Surface Labels')\n",
    "    axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(CONFIG['output_dir'] / 'data_visualization.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Visualization saved to outputs/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurfaceDetectionDataset(Dataset):\n",
    "    \"\"\"Dataset for surface detection training.\"\"\"\n",
    "    \n",
    "    def __init__(self, volume_patches, label_patches, augment=True):\n",
    "        self.volume_patches = volume_patches\n",
    "        self.label_patches = label_patches\n",
    "        self.augment = augment\n",
    "        \n",
    "        if augment:\n",
    "            self.aug_pipeline = VolumeAugmentationPipeline(\n",
    "                z_translation_prob=0.5,\n",
    "                max_z_shift=5,\n",
    "                image_size=volume_patches[0].shape[-1],\n",
    "                use_heavy_augs=True,\n",
    "                is_training=True\n",
    "            )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.volume_patches)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        volume = self.volume_patches[idx].copy()\n",
    "        label = self.label_patches[idx].copy()\n",
    "        \n",
    "        # Augmentation\n",
    "        if self.augment:\n",
    "            volume, label = self.aug_pipeline(volume, label)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        volume = torch.from_numpy(volume).float()  # (D, H, W)\n",
    "        label = torch.from_numpy(label).float().unsqueeze(0)  # (1, H, W)\n",
    "        \n",
    "        return {'image': volume, 'mask': label}\n",
    "\n",
    "print(\"‚úì Dataset class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Extract patches\n",
    "print(\"Extracting training patches...\")\n",
    "\n",
    "extractor = PatchExtractor(\n",
    "    patch_size=CONFIG['data']['patch_size'],\n",
    "    stride=CONFIG['data']['stride'],\n",
    "    balanced_sampling=True,\n",
    "    surface_ratio=0.5\n",
    ")\n",
    "\n",
    "vol_patches, label_patches, coords = extractor.extract_patches(\n",
    "    volume, mask, labels\n",
    ")\n",
    "\n",
    "print(f\"\\nExtracted {len(vol_patches)} patches\")\n",
    "print(f\"Patch shape: {vol_patches[0].shape}\")\n",
    "\n",
    "# Count surface vs non-surface\n",
    "surface_patches = sum(1 for lp in label_patches if lp.sum() > 0)\n",
    "print(f\"\\nSurface patches: {surface_patches}\")\n",
    "print(f\"Non-surface patches: {len(label_patches) - surface_patches}\")\n",
    "print(f\"Balance ratio: {surface_patches / len(label_patches) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/val split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_vol, val_vol, train_labels, val_labels = train_test_split(\n",
    "    vol_patches, label_patches,\n",
    "    test_size=CONFIG['data']['val_split'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_vol)}\")\n",
    "print(f\"Validation samples: {len(val_vol)}\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SurfaceDetectionDataset(train_vol, train_labels, augment=True)\n",
    "val_dataset = SurfaceDetectionDataset(val_vol, val_labels, augment=False)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG['training']['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=CONFIG['training']['num_workers'],\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CONFIG['training']['batch_size'] * 2,\n",
    "    shuffle=False,\n",
    "    num_workers=CONFIG['training']['num_workers'],\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Dataloaders ready!\")\n",
    "print(f\"   Train batches: {len(train_loader)}\")\n",
    "print(f\"   Val batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Model\n",
    "model = UNet3DDepthInvariant(\n",
    "    in_channels=CONFIG['model']['in_channels'],\n",
    "    out_channels=CONFIG['model']['out_channels'],\n",
    "    base_features=CONFIG['model']['base_features'],\n",
    "    depth=CONFIG['model']['depth']\n",
    ")\n",
    "\n",
    "print(f\"\\nModel: UNet3DDepthInvariant\")\n",
    "print(f\"Parameters: {count_parameters(model):,}\")\n",
    "print(f\"Base features: {CONFIG['model']['base_features']}\")\n",
    "print(f\"Depth: {CONFIG['model']['depth']}\")\n",
    "\n",
    "# Loss function\n",
    "loss_fn = CombinedLoss(\n",
    "    bce_weight=0.5,\n",
    "    dice_weight=0.5,\n",
    "    label_smoothing=0.1\n",
    ")\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=CONFIG['training']['learning_rate'],\n",
    "    weight_decay=1e-5\n",
    ")\n",
    "\n",
    "# Scheduler\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=CONFIG['training']['num_epochs'],\n",
    "    eta_min=1e-6\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Model initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    device=device,\n",
    "    scheduler=scheduler,\n",
    "    use_amp=CONFIG['training']['use_amp'],\n",
    "    checkpoint_dir=CONFIG['checkpoint_dir'],\n",
    "    use_wandb=False\n",
    ")\n",
    "\n",
    "print(\"‚úì Trainer initialized\")\n",
    "print(f\"   Mixed precision: {CONFIG['training']['use_amp']}\")\n",
    "print(f\"   Checkpoint dir: {CONFIG['checkpoint_dir']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# TRAINING - This will take 3-4 hours on Kaggle GPU\n",
    "print(\"=\"*60)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Epochs: {CONFIG['training']['num_epochs']}\")\n",
    "print(f\"This will take approximately {CONFIG['training']['num_epochs'] * 4:.0f} minutes\")\n",
    "print(\"\\nüí° TIP: After clicking 'Save & Run All', you can close your browser!\")\n",
    "print(\"   Kaggle will continue training in the cloud.\")\n",
    "print(\"   Come back later to check results.\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Train!\n",
    "trainer.fit(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=CONFIG['training']['num_epochs'],\n",
    "    save_every=CONFIG['training']['save_every']\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"TRAINING COMPLETE!\")\n",
    "print(f\"Total time: {elapsed/3600:.2f} hours\")\n",
    "print(f\"Best validation loss: {trainer.best_val_loss:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîü Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(trainer.train_losses, label='Train Loss')\n",
    "axes[0].plot(trainer.val_losses, label='Val Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training & Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning rate\n",
    "lrs = [optimizer.param_groups[0]['lr']] * len(trainer.train_losses)\n",
    "axes[1].plot(lrs)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Learning Rate')\n",
    "axes[1].set_title('Learning Rate Schedule')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(CONFIG['output_dir'] / 'training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Training curves saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model separately\n",
    "final_model_path = CONFIG['output_dir'] / 'final_model.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'config': CONFIG,\n",
    "    'best_val_loss': trainer.best_val_loss,\n",
    "}, final_model_path)\n",
    "\n",
    "print(f\"‚úì Final model saved to {final_model_path}\")\n",
    "print(f\"   File size: {final_model_path.stat().st_size / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_checkpoint = CONFIG['checkpoint_dir'] / 'best_model.pt'\n",
    "checkpoint = torch.load(best_checkpoint)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(f\"‚úì Loaded best model (val_loss: {checkpoint['best_val_loss']:.4f})\")\n",
    "\n",
    "# Predict on validation sample\n",
    "sample_idx = 0\n",
    "sample = val_dataset[sample_idx]\n",
    "\n",
    "with torch.no_grad():\n",
    "    image = sample['image'].unsqueeze(0).to(device)\n",
    "    pred_logits = model(image)\n",
    "    pred_probs = torch.sigmoid(pred_logits)\n",
    "    pred_binary = (pred_probs > 0.96).float()\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "axes[0].imshow(sample['image'][32].cpu(), cmap='gray')\n",
    "axes[0].set_title('Input (Slice 32)')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(sample['mask'][0].cpu(), cmap='hot')\n",
    "axes[1].set_title('Ground Truth')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(pred_probs[0, 0].cpu(), cmap='hot', vmin=0, vmax=1)\n",
    "axes[2].set_title('Prediction (Probability)')\n",
    "axes[2].axis('off')\n",
    "\n",
    "axes[3].imshow(pred_binary[0, 0].cpu(), cmap='gray')\n",
    "axes[3].set_title('Prediction (Binary, threshold=0.96)')\n",
    "axes[3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(CONFIG['output_dir'] / 'prediction_example.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Compute metrics\n",
    "dice = compute_dice(pred_logits, sample['mask'].unsqueeze(0).to(device))\n",
    "iou = compute_iou(pred_logits, sample['mask'].unsqueeze(0).to(device))\n",
    "\n",
    "print(f\"\\nMetrics on sample:\")\n",
    "print(f\"  Dice: {dice:.4f}\")\n",
    "print(f\"  IoU: {iou:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Done!\n",
    "\n",
    "### üì¶ Outputs (saved to `/kaggle/working/`):\n",
    "- `checkpoints/best_model.pt` - Best model checkpoint\n",
    "- `checkpoints/checkpoint_epoch_*.pt` - Intermediate checkpoints\n",
    "- `outputs/final_model.pth` - Final model weights\n",
    "- `outputs/training_curves.png` - Training visualization\n",
    "- `outputs/prediction_example.png` - Sample prediction\n",
    "\n",
    "### üì• Download Results:\n",
    "When notebook finishes:\n",
    "1. Click \"Output\" tab (top right)\n",
    "2. Download all files\n",
    "\n",
    "### üîÑ Next Steps:\n",
    "1. Try different fragments\n",
    "2. Increase epochs for better results\n",
    "3. Ensemble multiple models\n",
    "4. Apply to full scrolls\n",
    "\n",
    "### üí° Tips:\n",
    "- This notebook can run with **browser closed** if you use \"Save & Run All\"\n",
    "- Kaggle will continue training for up to 9 hours\n",
    "- Check back later to see results\n",
    "- Don't forget to save outputs before session expires!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
